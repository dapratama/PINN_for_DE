{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daa56a87",
   "metadata": {},
   "source": [
    "# PDE1-1: 1D Allen-Cahn Equation\n",
    "\n",
    "$$\n",
    "\\frac{∂u(x, t)}{∂t}+0.0001\\frac{∂^2u(x, t)}{∂x^2}+5u(x, t)^3-5u(x, t)=0\n",
    "$$\n",
    "\n",
    "with $x \\in [-1, 1]$, and $x \\in [0, 1]$. The boundary condition defined as:\n",
    "$$\n",
    "u(x, 0)=x^2 cos(\\pi x)\n",
    "$$\n",
    "$$\n",
    "u(t, -1)=u(t, 1) \\\\\n",
    "$$\n",
    "$$\n",
    "u_{x}(x, -1)=u_{x}(x, 1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38078f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import scipy.io\n",
    "from pyDOE import lhs\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data size on the solution\n",
    "data = scipy.io.loadmat('AC.mat')\n",
    "\n",
    "t = data['tt'].flatten()[:,None]\n",
    "x = data['x'].flatten()[:,None]\n",
    "exact = data['uu']\n",
    "exact_u = np.real(exact)\n",
    "\n",
    "x_grid, t_grid = np.meshgrid(x, t)\n",
    "\n",
    "# Preparing the x and t together as an input for predictions in one single array, as data_all\n",
    "data_all = np.hstack((x_grid.flatten()[:, None], t_grid.flatten()[:, None]))\n",
    "\n",
    "# Preparing the exact solution in similar position correspond with each combination input x and t\n",
    "data_exact = exact_u.flatten()[:, None]\n",
    "\n",
    "# Determine how much points for training in both boundary condition and PDE itself\n",
    "N_b = 50\n",
    "N_u = 1500\n",
    "\n",
    "# Bounday condition and exact value when u(x, 0) (left)\n",
    "xx1 = np.hstack((x_grid[0:1, :].T, t_grid[0:1, :].T))\n",
    "idx1 = np.random.choice(xx1.shape[0], N_b, replace=False)\n",
    "xx1_b = xx1[idx1, :]\n",
    "uu1 = exact_u[:, 0:1]\n",
    "uu1_b = uu1[idx1, :]\n",
    "\n",
    "# Bounday condition and exact value when u(x, 1) (right)\n",
    "xx2 = np.hstack((x_grid[0:1, :].T, t_grid[-1:, :].T))\n",
    "idx2 = np.random.choice(xx2.shape[0], N_b, replace=False)\n",
    "xx2_b = xx2[idx2, :]\n",
    "uu2 = exact_u[:, -1:]\n",
    "uu2_b = uu2[idx2, :]\n",
    "\n",
    "# Bounday condition and exact value when u(-1, t) (bottom)\n",
    "xx3 = np.hstack((x_grid[:, 0:1], t_grid[:, 0:1]))\n",
    "idx3 = np.random.choice(xx3.shape[0], N_b, replace=False)\n",
    "xx3_b = xx3[idx3, :]\n",
    "uu3 = exact_u[0:1, :].T\n",
    "uu3_b = uu3[idx3, :]\n",
    "\n",
    "# Bounday condition and exact value when u(1, t) (top)\n",
    "xx4 = np.hstack((x_grid[:, -1:], t_grid[:, -1:]))\n",
    "idx4 = np.random.choice(xx4.shape[0], N_b, replace=False)\n",
    "xx4_b = xx4[idx4, :]\n",
    "uu4 = exact_u[-1:, :].T\n",
    "uu4_b = uu4[idx4, :]\n",
    "\n",
    "# Stacking all boundary condition the exact value in single variable\n",
    "data_b_all = np.vstack([xx1, xx2, xx3, xx4])\n",
    "exact_b_all = np.vstack([uu1, uu2, uu3, uu4])\n",
    "\n",
    "xx = [xx1, xx2, xx3, xx4]\n",
    "uu = [uu1, uu2, uu3, uu4]\n",
    "\n",
    "idx_b = [np.random.choice(x.shape[0], N_b, replace=False) for x in xx]\n",
    "\n",
    "data_b_train = np.vstack([xx1_b, xx2_b, xx3_b, xx4_b])\n",
    "exact_b_train = np.vstack([uu1_b, uu2_b, uu3_b, uu4_b])\n",
    "\n",
    "# Domain bounds (lowerbounds upperbounds) [x, t], which are here ([0, 0]) and ([1, 1])\n",
    "lb = data_all.min(axis=0)\n",
    "ub = data_all.max(axis=0)\n",
    "\n",
    "# Preparing the training data inside PDE domain\n",
    "data_u_train = lb + (ub-lb)*lhs(2, N_u)\n",
    "\n",
    "idx = np.random.choice(data_u_train.shape[0], N_u, replace=False)\n",
    "\n",
    "exact_u_train = data_exact[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86486a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import RectBivariateSpline\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=[12, 4])\n",
    "\n",
    "axs[0].set_title(\"Collocation and initial/boundary training points\", fontsize=15, fontweight ='bold')\n",
    "axs[0].set_xlabel('t', fontsize=12, fontweight ='bold')\n",
    "axs[0].set_ylabel('x', fontsize=12, fontweight ='bold')\n",
    "axs[0].vlines(x = 0, ymin = -1, ymax = 1, color='black', linewidth = 1)\n",
    "axs[0].vlines(x = 1, ymin = -1, ymax = 1, color='black', linewidth = 1)\n",
    "axs[0].hlines(y = -1, xmin = 0, xmax = 1, color='black', linewidth = 1)\n",
    "axs[0].hlines(y = 1, xmin = 0, xmax = 1, color='black', linewidth = 1)\n",
    "dot = axs[0].scatter(data_u_train[:,1], data_u_train[:,0], s=5, marker='o', label = 'PDE points', clip_on = False)\n",
    "cross1 = axs[0].scatter(data_b_train[:,1], data_b_train[:,0], s=10, marker='x', label = 'Boundary points', \n",
    "                  linewidth = 2, clip_on = False)\n",
    "cross2 = axs[0].scatter(data_b_train[:50][:,1], data_b_train[:50][:,0], s=10, marker='x', color='red', label = 'Initial points', \n",
    "                  linewidth = 2, clip_on = False)\n",
    "axs[0].get_xaxis().set_visible(True)\n",
    "axs[0].get_yaxis().set_visible(True)\n",
    "\n",
    "axs[0].legend(handles=[dot, cross2, cross1], labels=['Collocation points', 'Initial points', 'Boundary points'], loc='upper center', \n",
    "           bbox_to_anchor=(0.5, -0.1), ncol=3, frameon=False)\n",
    "\n",
    "cax = axs[1].contourf(t_grid, x_grid, exact_u.T, 50, cmap='jet', origin='lower')\n",
    "axs[1].set_title('Ground-truth solution', fontsize=15, fontweight='bold')\n",
    "#ax1.get_xaxis().set_visible(False)\n",
    "axs[1].set_xlabel('t', fontsize=12, fontweight='bold')\n",
    "axs[1].set_ylabel('x', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = fig.colorbar(cax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a92b10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.activations import tanh\n",
    "\n",
    "class FLANNLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, degree, activation=None, minval=-0.05, maxval=0.05, **kwargs):\n",
    "        super(FLANNLayer, self).__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.degree = degree\n",
    "        self.function_type = function_type\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        self.minval = minval\n",
    "        self.maxval = maxval\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.feature_size = (self.degree + 1) * input_shape[1]\n",
    "        self.kernel = self.add_weight(\n",
    "            name='kernel',\n",
    "            shape=(self.feature_size, self.output_dim),\n",
    "            initializer=tf.keras.initializers.HeNormal(),\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def apply_activation(self, x):\n",
    "        if self.activation is not None:\n",
    "            return self.activation(x)\n",
    "        return x\n",
    "\n",
    "    def legendre_polynomials(self, x, degree):\n",
    "        batch_size, input_dim = tf.shape(x)[0], tf.shape(x)[1]\n",
    "        P = [self.apply_activation(tf.ones((batch_size, input_dim), dtype=x.dtype)), self.apply_activation(x)]\n",
    "        for n in range(2, degree + 1):\n",
    "            Pn = ((2.0 * n - 1.0) * x * P[n - 1] - (n - 1.0) * P[n - 2]) / n\n",
    "            P.append(self.apply_activation(Pn))\n",
    "        return P\n",
    "\n",
    "    def call(self, inputs):\n",
    "        F = self.legendre_polynomials(inputs, self.degree)\n",
    "        outputs = tf.concat(F, axis=1)\n",
    "        outputs = tf.matmul(outputs, self.kernel)\n",
    "        if self.activation is not None:\n",
    "            outputs = self.apply_activation(outputs)\n",
    "        return outputs\n",
    "\n",
    "keras.utils.get_custom_objects()[\"FLANNLayer\"] = FLANNLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe1a478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.activations import tanh\n",
    "\n",
    "class PINN:\n",
    "    def __init__(self, data_u_train, exact_u_train, data_b_train, exact_b_train, optimizer):\n",
    "        self.data_u_train = data_u_train\n",
    "        self.exact_u_train = exact_u_train\n",
    "        self.data_b_train = data_b_train\n",
    "        self.exact_b_train = exact_b_train\n",
    "        self.optimizer = optimizer\n",
    "        self.build_model()\n",
    "        \n",
    "    def build_model(self):\n",
    "        # Define input layer\n",
    "        inputs = tf.keras.Input(shape=self.data_u_train.shape[1:])\n",
    "        \n",
    "        dense1 = Dense(50, activation='tanh')(inputs)\n",
    "        dense2 = Dense(50, activation='tanh')(dense1)\n",
    "        dense3 = Dense(50, activation='tanh')(dense2)\n",
    "        dense4 = Dense(50, activation='tanh')(dense3)\n",
    "        flann = FLANNLayer(output_dim=50, degree=5, function_type='legendre', activation='tanh')(dense4)\n",
    "        outputs = Dense(1)(flann)\n",
    "\n",
    "        # Define the model\n",
    "        self.model_nn = Model(inputs=inputs, outputs=outputs)\n",
    "        self.model_nn.compile(optimizer=self.optimizer, loss=self.__loss)\n",
    "        \n",
    "        # Initialize the history list\n",
    "        self.history = {\"loss\": [], \"val_loss\": []}\n",
    "        \n",
    "    def fit_model(self, epochs):\n",
    "        earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "        checpoint_cb = keras.callbacks.ModelCheckpoint('pde11_lel_pinn.h5', monitor='val_loss', save_best_only=True)\n",
    "        history_callback = self.model_nn.fit(self.data_u_train, self.exact_u_train, epochs=epochs,\n",
    "                          callbacks=[checpoint_cb], verbose=1, validation_split=0.25)\n",
    "        self.history[\"loss\"].append(history_callback.history[\"loss\"])\n",
    "        self.history[\"val_loss\"].append(history_callback.history[\"val_loss\"])\n",
    "\n",
    "    def u_model(self):\n",
    "        x_f = tf.convert_to_tensor(self.data_u_train[:, 0:1], dtype=tf.float32)\n",
    "        t_f = tf.convert_to_tensor(self.data_u_train[:, 1:2], dtype=tf.float32)\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(x_f)\n",
    "            tape.watch(t_f)\n",
    "            with tf.GradientTape(persistent=True) as gtape:\n",
    "                gtape.watch(x_f)\n",
    "                gtape.watch(t_f)\n",
    "                input = tf.stack([x_f[:, 0], t_f[:, 0]], axis=1)\n",
    "                u = self.model_nn(input)\n",
    "            u_x = gtape.gradient(u, x_f)\n",
    "            u_t = gtape.gradient(u, t_f)\n",
    "            del gtape\n",
    "        u_xx = tape.gradient(u_x, x_f)\n",
    "        del tape\n",
    "        \n",
    "        return u_t - 0.0001*u_xx + 5.0*(u)**3 - 5.0*u\n",
    "    \n",
    "    def u_x_model(self, data_b_train):\n",
    "        x_b = tf.convert_to_tensor(data_b_train[:, 0:1], dtype=tf.float32)\n",
    "        t_b = tf.convert_to_tensor(data_b_train[:, 1:2], dtype=tf.float32)\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            tape.watch(x_b)\n",
    "            tape.watch(t_b)\n",
    "            X_b = tf.stack([x_b[:, 0], t_b[:, 0]], axis=1)\n",
    "            u = self.model_nn(X_b)\n",
    "        u_x = tape.gradient(u, x_b)\n",
    "        del tape\n",
    "        return u, u_x\n",
    "\n",
    "    def __loss(self, data_u_train, exact_u_train):\n",
    "        data_b_0 = tf.convert_to_tensor(self.data_b_train[:50], dtype=tf.float32) #init\n",
    "        data_b_1 = tf.convert_to_tensor(self.data_b_train[50:100], dtype=tf.float32) #right\n",
    "        data_b_2 = tf.convert_to_tensor(self.data_b_train[100:150], dtype=tf.float32) #bottom\n",
    "        data_b_3 = tf.convert_to_tensor(self.data_b_train[150:200], dtype=tf.float32) #top\n",
    "        \n",
    "        exact_b_0 = tf.convert_to_tensor(self.exact_b_train[:50], dtype=tf.float32) #exact init\n",
    "        exact_b_1 = tf.convert_to_tensor(self.exact_b_train[50:100], dtype=tf.float32) #exact right\n",
    "        exact_b_2 = tf.convert_to_tensor(self.exact_b_train[100:150], dtype=tf.float32) #exact bottom\n",
    "        exact_b_3 = tf.convert_to_tensor(self.exact_b_train[150:200], dtype=tf.float32) #exact top\n",
    "        \n",
    "        init_pred, _ = self.u_x_model(data_b_0)\n",
    "        right_pred, _ = self.u_x_model(data_b_1)\n",
    "        uub_pred, uub_x_pred = self.u_x_model(data_b_3)\n",
    "        ulb_pred, ulb_x_pred = self.u_x_model(data_b_2)\n",
    "        u_pred = self.u_model()\n",
    "    \n",
    "        loss_0 = tf.reduce_mean(tf.square(init_pred - (data_b_0[:, 0:1]**2)*tf.math.cos(np.pi*data_b_0[:, 0:1])) + \\\n",
    "                               tf.square(right_pred - exact_b_1))\n",
    "        loss_b = tf.reduce_mean(tf.square(ulb_pred - exact_b_2) + tf.square(ulb_pred - exact_b_3) + \\\n",
    "                                tf.square(ulb_x_pred - uub_x_pred))\n",
    "        loss_u = tf.reduce_mean(tf.square(u_pred))\n",
    "\n",
    "        return loss_0 + loss_b + loss_u\n",
    "    \n",
    "    def predict(self, x):\n",
    "        prediction = self.model_nn.predict(x)\n",
    "        return prediction\n",
    "    \n",
    "    keras.utils.get_custom_objects()[\"__loss\"] = __loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225765c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "pde_pinn = PINN(data_u_train, exact_u_train, data_b_train, exact_b_train, optimizer)\n",
    "pde_pinn.model_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783ea487",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.perf_counter()\n",
    "for i in range(1):\n",
    "    print('cycle:------------------------------------', i+1)\n",
    "    pde_pinn.fit_model(epochs=2000)\n",
    "    pde_pinn.model_nn.load_weights('pde11_lel_pinn.h5')\n",
    "        \n",
    "elapsed = time.perf_counter() - start\n",
    "print('Elapsed %.3f seconds.' % elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46779a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(1, 1, figsize=[5, 3])\n",
    "axs.set_facecolor('lightgrey')\n",
    "axs.grid(which='major', color='black', linestyle='--', linewidth=0.5)\n",
    "axs.plot(pde_pinn.history[\"loss\"][0], label='LEL-PINN Train Loss', color='black')\n",
    "axs.plot(pde_pinn.history[\"val_loss\"][0], label='LEL-PINN Test Loss', color='orange')\n",
    "axs.set_yscale('log')\n",
    "axs.set_xlim([-50, 2050])\n",
    "axs.set_ylim([5e-6, 5e+0])\n",
    "axs.set_xlabel('Iter', fontsize=12, fontweight ='bold')\n",
    "axs.set_ylabel('Loss value', fontsize=12, fontweight ='bold', x=0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ee4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "lel_pinn_prediction = pde_pinn.predict(data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd8cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import format_float_scientific\n",
    "\n",
    "index = pde_pinn.history[\"val_loss\"][0].index(min(pde_pinn.history[\"val_loss\"][0]))\n",
    "\n",
    "print(format_float_scientific(pde_pinn.history[\"loss\"][0][index], exp_digits=2, precision=3))\n",
    "print(format_float_scientific(pde_pinn.history[\"val_loss\"][0][index], exp_digits=2, precision=3))\n",
    "print(len(pde_pinn.history[\"val_loss\"][0]))\n",
    "print('%.2f'%(elapsed/len(pde_pinn.history[\"val_loss\"][0])))\n",
    "print('%.2f'%elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813f4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "fig = plt.figure(figsize=[8, 5])  # Increased height to fit additional subplots\n",
    "\n",
    "lel_pinn_value_pred = lel_pinn_prediction.reshape((t.shape[0], x.shape[0]))\n",
    "\n",
    "# Create a grid with 2 rows and 3 columns; the first row will span all three columns for the main plot\n",
    "gs = GridSpec(2, 3, height_ratios=[3, 1], hspace=0.4)  # Adjust `height_ratios` as needed\n",
    "\n",
    "line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
    "\n",
    "# Adjust main plot to fully align with bottom plots\n",
    "axs_main = fig.add_axes([0.12, 0.4, 0.82, 0.55])  # [left, bottom, width, height]\n",
    "divider = make_axes_locatable(axs_main)\n",
    "\n",
    "# Create contour plot\n",
    "axs_main.set_title('$u(x, t)$ LEL-PINN Prediction', fontsize=12, fontweight='bold')\n",
    "cax = axs_main.contourf(t_grid, x_grid, lel_pinn_value_pred, 50, cmap='jet', origin='lower')\n",
    "axs_main.plot(t[40] * np.ones((2, 1)), line, 'k--', linewidth=1)\n",
    "axs_main.plot(t[100] * np.ones((2, 1)), line, 'k--', linewidth=1)\n",
    "axs_main.plot(t[160] * np.ones((2, 1)), line, 'k--', linewidth=1)\n",
    "axs_main.set_xlabel('t', fontsize = 12, fontweight='bold')\n",
    "axs_main.set_ylabel('x', fontsize = 12, fontweight='bold')\n",
    "\n",
    "# Create an axis for the colorbar outside the plot\n",
    "cbar_ax = divider.append_axes(\"right\", size=\"3%\", pad=0.1)\n",
    "colorbar = plt.colorbar(cax, cax=cbar_ax)\n",
    "colorbar.set_label('$u(x, t)$')  # Label for colorbar\n",
    "\n",
    "lel_pinn_u_pred = griddata(data_all, lel_pinn_prediction.flatten(), (x_grid, t_grid), method='cubic')\n",
    "\n",
    "# Small subplots on the second row\n",
    "axs1 = fig.add_subplot(gs[1, 0])\n",
    "axs1.set_facecolor('lightgrey')\n",
    "axs1.grid(which='major', color='black', linestyle='--', linewidth=0.5)\n",
    "axs1.plot(x, exact_u.T[40,:], alpha=0.5, ls='-', lw=5,)\n",
    "axs1.plot(x, lel_pinn_u_pred[40,:], ls='--', lw=1, color='blue')\n",
    "axs1.set_ylim([-1.25, 1.25])\n",
    "axs1.set_title('$u(x, t)$ at $t=%.2f$' % (t[40]), fontsize=8)\n",
    "axs1.set_ylabel('$u(x, t)$', fontsize = 8, fontweight='bold')\n",
    "\n",
    "axs2 = fig.add_subplot(gs[1, 1])\n",
    "axs2.set_facecolor('lightgrey')\n",
    "axs2.grid(which='major', color='black', linestyle='--', linewidth=0.5)\n",
    "axs2.plot(x, exact_u.T[100,:], alpha=0.5, ls='-', lw=5,)\n",
    "axs2.plot(x, lel_pinn_u_pred[100,:], ls='--', lw=1, color='blue')\n",
    "axs2.set_ylim([-1.25, 1.25])\n",
    "axs2.set_title('$u(x, t)$ at $t=%.2f$' % (t[100]), fontsize=8)\n",
    "axs2.set_xlabel('x', fontsize = 8, fontweight='bold')\n",
    "\n",
    "axs3 = fig.add_subplot(gs[1, 2])\n",
    "axs3.set_facecolor('lightgrey')\n",
    "axs3.grid(which='major', color='black', linestyle='--', linewidth=0.5)\n",
    "axs3.plot(x, exact_u.T[160,:], alpha=0.5, ls='-', lw=5, label = 'Ground-truth sol')\n",
    "axs3.plot(x, lel_pinn_u_pred[160,:], ls='--', lw=1, color='blue', label='LEL-PINN')\n",
    "axs3.set_ylim([-1.25, 1.25])\n",
    "axs3.set_title('$u(x, t)$ at $t=%.2f$' % (t[160]), fontsize=8)\n",
    "\n",
    "axs3.legend(loc='upper center', bbox_to_anchor=(-0.7, -0.4), ncol=4, frameon=False)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba023ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
